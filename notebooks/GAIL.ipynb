{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import gymnasium as gym\n",
    "import h5py\n",
    "import mani_skill2.envs\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imitation.algorithms.adversarial.gail import GAIL\n",
    "from imitation.data.types import Trajectory\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from imitation.rewards.reward_nets import BasicRewardNet\n",
    "from imitation.util.logger import configure\n",
    "from imitation.util.networks import RunningNorm\n",
    "from imitation.util.util import make_vec_env\n",
    "from mani_skill2.utils.wrappers import RecordEpisode\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import (DummyVecEnv, SubprocVecEnv,\n",
    "                                              VecFrameStack)\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from torch.nn import (Flatten, Linear, TransformerEncoder,\n",
    "                      TransformerEncoderLayer)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.dataset import StackDatasetOriginalSequential\n",
    "from utils.data_utils import flatten_obs, make_path\n",
    "from utils.train_utils import init_deque, update_deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ckpt_path = make_path('GAIL', 'checkpoints')\n",
    "log_path = make_path('GAIL', 'logs')\n",
    "tensorboard_path = make_path('GAIL', 'logs', 'tensorboard')\n",
    "data_path = os.path.join('..', 'datasets', 'trajectory_state_original.h5')\n",
    "\n",
    "Path(ckpt_path).mkdir(exist_ok=True, parents=True)\n",
    "Path(log_path).mkdir(exist_ok=True, parents=True)\n",
    "Path(tensorboard_path).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare trajectory for imitation package\n",
    "def prep_trajectory(file_path: str) -> List[Trajectory]:\n",
    "    traj_list = []\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        for traj_key in file.keys():\n",
    "            traj_data = file[traj_key]\n",
    "            obs = flatten_obs(traj_data['obs'])\n",
    "            acts = np.array(traj_data['actions'])\n",
    "            traj = Trajectory(obs, acts, infos=None, terminal=True)\n",
    "            traj_list.append(traj)\n",
    "    return traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# venv = make_vec_env(\n",
    "#     \"StackCube-v0\",\n",
    "#     rng=np.random.default_rng(seed=42),\n",
    "#     parallel=False,\n",
    "#     n_envs=1,\n",
    "#     log_dir=log_path,\n",
    "#     max_episode_steps=250,\n",
    "#     post_wrappers=[lambda env, _: RolloutInfoWrapper(env)],\n",
    "#     env_make_kwargs=dict(obs_mode='state',\n",
    "#                          control_mode='pd_joint_delta_pos',\n",
    "#                          reward_mode='normalized_dense',\n",
    "#                          render_mode='cameras')\n",
    "# )\n",
    "# stack_env = VecFrameStack(venv, n_stack=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "trajectories = prep_trajectory(data_path)\n",
    "\n",
    "venv = make_vec_env(\n",
    "    \"StackCube-v0\",\n",
    "    rng=np.random.default_rng(seed=SEED),\n",
    "    parallel=False,\n",
    "    n_envs=4,\n",
    "    log_dir=log_path,\n",
    "    max_episode_steps=250,\n",
    "    post_wrappers=[lambda env, _: RolloutInfoWrapper(env)],\n",
    "    env_make_kwargs=dict(obs_mode='state',\n",
    "                         control_mode='pd_joint_delta_pos',\n",
    "                         reward_mode='normalized_dense',\n",
    "                         render_mode='cameras')\n",
    ")\n",
    "\n",
    "\n",
    "learner = PPO(\n",
    "    env=venv,\n",
    "    policy=MlpPolicy,\n",
    "    batch_size=64,\n",
    "    ent_coef=1e-6,\n",
    "    learning_rate=0.0004,\n",
    "    gamma=0.95,\n",
    "    n_epochs=5,\n",
    "    seed=SEED,\n",
    "    tensorboard_log=tensorboard_path\n",
    ")\n",
    "\n",
    "\n",
    "reward_net = BasicRewardNet(\n",
    "    observation_space=venv.observation_space,\n",
    "    action_space=venv.action_space,\n",
    "    normalize_input_layer=RunningNorm,\n",
    ")\n",
    "\n",
    "\n",
    "gail_trainer = GAIL(\n",
    "    demonstrations=trajectories,\n",
    "    demo_batch_size=1024,\n",
    "    gen_replay_buffer_capacity=512,\n",
    "    n_disc_updates_per_round=8,\n",
    "    venv=venv,\n",
    "    gen_algo=learner,\n",
    "    reward_net=reward_net,\n",
    "    allow_variable_horizon=True,\n",
    "    log_dir=log_path,\n",
    "    init_tensorboard=True,\n",
    "    init_tensorboard_graph=True,\n",
    "    custom_logger=configure(log_path, ('tensorboard', 'stdout', 'csv'))\n",
    ")\n",
    "\n",
    "\n",
    "# venv.seed(SEED)\n",
    "# learner_rewards_before_training, _ = evaluate_policy(model=learner,\n",
    "#                                                      env=venv,\n",
    "#                                                      n_eval_episodes=100,\n",
    "#                                                      return_episode_rewards=True)\n",
    "\n",
    "\n",
    "# train the learner and evaluate again\n",
    "ckpts = 10\n",
    "steps_per_ckpt = 100_000\n",
    "for ckpt in range(1, ckpts+1):\n",
    "    gail_trainer.train(steps_per_ckpt)\n",
    "    learner.save(os.path.join(ckpt_path, f'PPO_{ckpt*steps_per_ckpt}'))\n",
    "    torch.save(reward_net.state_dict(), os.path.join(ckpt_path, f'Reward_{ckpt*steps_per_ckpt}'))\n",
    "\n",
    "# venv.seed(SEED)\n",
    "# learner_rewards_after_training, _ = evaluate_policy(model=learner,\n",
    "#                                                     env=venv,\n",
    "#                                                     n_eval_episodes=100,\n",
    "#                                                     return_episode_rewards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/u/xgu3km/cs6501/NP-RAM/venv/lib/python3.8/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/u/xgu3km/cs6501/NP-RAM/venv/lib/python3.8/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e69da0dd0a4a3e9fe3edab24c7ee13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.learn(total_timesteps=100_000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('StackCube-v0',\n",
    "                render_mode=\"cameras\",\n",
    "                enable_shadow=True,\n",
    "                obs_mode=\"state\",\n",
    "                control_mode=\"pd_joint_delta_pos\", \n",
    "                max_episode_steps=400)\n",
    "\n",
    "env = RecordEpisode(\n",
    "    env,\n",
    "    log_path,\n",
    "    info_on_video=True,\n",
    "    save_trajectory=False\n",
    ")\n",
    "\n",
    "\n",
    "obs, _ = env.reset()\n",
    "\n",
    "action, info = learner.predict(obs, deterministic=True)\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    while not terminated and not truncated:\n",
    "        action, info = learner.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "env.flush_video(suffix=f'GAIL')\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
